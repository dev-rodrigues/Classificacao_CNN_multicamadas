# -*- coding: utf-8 -*-
"""at - games - questao 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AuKym58bjfkm1JI0TfDlLxgBQXEurs3P
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import CIFAR10
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler

import matplotlib.pyplot as plt

import numpy as np
import random
from tqdm import tqdm

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

# Número de sub-processos para leitura de dados
num_workers = 0

# Tamanho do lote de dados
batch_size = 64

# Porcentagem dos dados de teste que serão utilizados para validação
validation_size = 0.2

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])

# Carregar conjunto de dados CIFAR-10
trainset = CIFAR10('data', train=True, download=True, transform=transform)
testdata = CIFAR10('data', train=False, download=True, transform=transform)

num_total_train = len(trainset)
idx_total = list(range(num_total_train))
np.random.shuffle(idx_total)
split = int(np.floor(validation_size * num_total_train))

train_idx, valid_idx = idx_total[split:], idx_total[:split]

train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)

train_loader = DataLoader(trainset, batch_size=batch_size,
                          sampler=train_sampler, num_workers=num_workers)

valid_loader = DataLoader(trainset, batch_size=batch_size,
                          sampler=valid_sampler, num_workers=num_workers)

test_loader = DataLoader(testdata, batch_size=batch_size, num_workers=num_workers)

# Obter as classes disponíveis no conjunto de dados
classes = trainset.classes

print("Classes disponíveis no conjunto de dados:", classes)

datasets = {"train": train_loader, "validation": valid_loader, "test": test_loader}

for dataset in datasets.keys():
  sample, lbl = next(iter(datasets[dataset]))
  num_samples = len(sample)

  print(f"Tamanho do conjunto de {dataset}: {num_samples * batch_size}")

class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()

        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU())

        self.layer2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.layer3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU())

        self.layer4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.layer5 = nn.Sequential(
            nn.Linear(64 * 8 * 8, 128),
            nn.ReLU())

        self.layer6 = nn.Sequential(
            nn.Linear(128, num_classes),
            nn.Softmax(dim=1))

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = out.view(out.size(0), -1)
        out = self.layer5(out)
        out = self.layer6(out)
        return out

num_classes = len(trainset.classes)
model = CNN(num_classes)

model.to(device)

# definir funcao de perda e otimizador
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Treinamento do modelo
num_epochs = 10

# treino

for epoch in range(num_epochs):
    model.train()  # Modo de treinamento

    with tqdm(total=len(train_loader), unit='batch') as pbar:
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            pbar.set_description(f"Epoch [{epoch + 1}/{num_epochs}]")
            pbar.set_postfix(loss=loss.item())
            pbar.update(1)

print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}")

# calcula a perda (test loss), a acurácia (test accuracy) para cada classe e a acurácia total no conjunto de teste.
test_loss = 0.
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))

model.eval()
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)
        test_loss += loss.item()

        ps = torch.exp(outputs)
        _, pred = torch.max(ps, 1)
        correct_tensor = pred.eq(labels.data.view_as(pred))
        correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())

        for i in range(len(labels)):
            idx_label = labels.data[i]
            class_correct[idx_label] += correct[i].item()
            class_total[idx_label] += 1

test_loss = test_loss / len(test_loader)
print(f"Test Loss: {test_loss}")

for i in range(10):
    if class_total[i] > 0:
        accuracy = (class_correct[i] / class_total[i]) * 100
        print(f"Test Accuracy of class {classes[i]}: {round(accuracy, 2)}% \t{class_correct[i]} / {class_total[i]}")

total_acc = (np.sum(class_correct) / np.sum(class_total)) * 100
print(f"Total accuracy is: {total_acc}")

# Visualização das imagens, classes correspondentes e descrição da classificação
model.eval()
with torch.no_grad():
    count = 0
    num_columns = 4

    fig, axs = plt.subplots(nrows=4, ncols=num_columns, figsize=(12, 12))

    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        for i in range(images.size(0)):
            sample_image = images[i].cpu().numpy()
            sample_label = labels[i].item()
            predicted_label = predicted[i].item()

            ax = axs[count // num_columns, count % num_columns]
            ax.imshow(np.transpose(sample_image, (1, 2, 0)))
            ax.set_title(f"True Label: {classes[sample_label]}, Predicted Label: {classes[predicted_label]}")
            ax.axis('off')

            count += 1

            if count == 16:
                break

        if count == 16:
            break

    plt.tight_layout()
    plt.show()
